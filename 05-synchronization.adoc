[#05-synchronization]
= Synchronization

include::chapter-include.adoc[]

[quote,Sherlock Holmes,"The Adventures of Sherlock Holmes by Arthur Conan Doyle"]
It is a capital mistake to theorize before one has data.

Data are the lifeblood of any software system.
Ensuring proper management of the data is one of the primary responsibilities of a software architect.
But data management can be very tricky – as any experienced software architect knows only too well.
One of the important principle of software architecture is often formulated as "do not repeat yourself".
This applies to code as it applies to data: though shall not repeat the data.
There is one original, authoritative value.
And there should not be any copies of that value.
Ever.
There is just one universal source of truth.
If there are no copies then the data are always consistent.
No copies means no contradictions.
Just one truth, precise and crystal-clear.
Keep data in one place and one place only.

That is the theory.

However, practice has a different opinion to offer.
In practice there are many incompatible technologies.
Applications built on relational databases cannot directly use data from directory services.
Even relational databases do not fit together easily.
Each application is designed with a different data model in mind.
There are data translation and bridging technologies that work as adapters to resolve compatibility issues.
Those are elegant solutions.
But there is a cost to pay.
The adapters add latencies and they almost always have major negative impact on performance.
Even worse, transaction handling and data consistency is very problematic.
Such adapters are additional components on a critical path and their failures are very painful.
The resulting system is often operationally fragile: failure of even a minor component means a failure of the entire system.
Not to speak about the enormous complexity and cost of the solution.

On the other hand, copying all the data into my application database is so convenient.
The application can access the data easily, using just one homogeneous mechanism.
Failure of other components are not affecting the critical path.
And it is all so much better for performance.
Copying the data solves almost all the troublesome issues.
Except for one small detail: the problem of keeping the data up to date.
And that is where the synchronization mechanisms come in.

However hard you may try, it is almost impossible to avoid maintaining copies of the data.
Identity data are no exception.
In fact identity data are often the most heavily affected.
And it makes a lot of sense.
Applications are built for users to use them.
Therefore almost every application keeps some kind of data about users.
In addition to that, such data are usually very sensitive from security and privacy point of view.

We cannot avoid copying the data.
The best thing that we can do is to keep the copies managed and synchronized.
Some applications have built-in support for LDAP or directory synchronization.
But those mechanisms are usually quite weak and fragile.
For example many applications provide capability for on-demand synchronization with directory service on login time.
It usually works like this:

. User enters username and password to application login dialog.

. The application connects to the directory service to validate the password.

. If the password is correct then the application retrieves user data from the directory.

. The application stores copy of user data locally.

. Business as usual.
Local copy of the data is used ever since.

This approach works quite well at the beginning.
But after a while the data begin to stink.
Users are renamed, but the local copies are not updated.
Users are deleted, but the local copies stay around forever.
There are local accounts and privileges that are not reflected back to the directory service and therefore remain undetected for years.
Which means that we have a serious security and data protection problem here.
And we do not even know that the problem is there.

Some applications have more advanced synchronization processes that can do better than this.
However, an application that does synchronization well is still an extremely rare sight.
And there is a good reason for this.
Synchronization is much harder than it seems.
There may be data inconsistencies on both sides.
There may be networking errors.
Configuration errors.
Data models are evolving in time.
Policies are changing.
It is no easy task to reliably synchronize the data in such environment.
Therefore there is a special breed of systems that specialize in synchronization of identity data: identity management systems.

== Synchronization in MidPoint

Synchronization is one of the basic mechanisms of midPoint.
Synchronization mechanisms are integral part of midPoint design from its very beginning.
Many of the things that midPoint normally does are in fact just different flavors of synchronization.
There are obvious cases such as reconciliation process synchronizing account attributes with midPoint user properties.
But there are also less obvious cases, such as a completely ordinary provisioning case when midPoint needs to create a new account for a user.
Even that case is in fact a synchronization: midPoint user properties are synchronized with a new empty account on the resource.
Majority of midPoint operations are directly or indirectly using the synchronization principles.

TIP: Reuse of the mechanisms is one of fundamental principles of midPoint design.
When we have designed midPoint we have not invented a separate mechanism for every midPoint feature.
We have rather designed few very generic principles that are re-used at many places in midPoint.
Synchronization is one of these principles.
There is one code that implements the core of the synchronization logic.
And that code is used whenever we need to "align" objects that relate to each other.
The same code is used for user-account reconciliation, ordinary provisioning, role-based provisioning, live synchronization, data consistency ... almost everywhere.

MidPoint synchronization is almost a continuous functionality spectrum that can be tweaked and tuned to match specific needs.
Yet, the synchronization mechanisms can be divided to several broad and slightly overlapping categories:

* *Live synchronization* is almost real-time synchronization mechanism.
MidPoint continually scans the resource for changes.
If changes are detected then those changes are immediately processed by midPoint.
The actual latencies depend on the capabilities of the resource but usual numbers range from few seconds to few minutes.
Only recent changes are processed by live synchronization.
Therefore it is a very efficient mechanism which usually has fast responses even in large-scale deployments.

* *Reconciliation* is a process that compares the data and corrects them.
When an account is reconciled, midPoint computes the attribute values that the account should have.
The computed values are compared to the real values that the account has.
Any differences are corrected.
Reconciliation is quite heavy-weight mechanism, comparing all the accounts one-by-one.
But it is also a very reliable mechanism.
It can correct mistakes that were missed by live synchronization, it can correct data after major failures and corruptions and so on.
Reconciliation is usually executed in regular intervals.
However due to its nature it is usually executed during off-peak times (nights and weekends).

* *Import* is usually a one-time process to get data from the resource to midPoint.
Import is used to populate midPoint with initial data or it may be used to connect a new resource to midPoint.
Import is almost the same as reconciliation with only a few minor differences.
However its purpose is different and therefore there is usually also a slightly different configuration of import policies (mappings).
Import is usually not scheduled, it is manually triggered when needed.

* *Opportunistic synchronization* is a very special kind of animal which is quite unique to midPoint.
Opportunistic synchronization is triggered automatically when midPoint discovers that something is not in order.
For example if midPoint tries to modify an account, but it discovers that the account is not there.
Then a synchronization mechanism is triggered just for that single account.
This usually means that the account is re-created.
The opportunistic synchronization is also triggered when midPoint tries to create a new account, but the account is already there.
This approach makes midPoint a self-healing system.
If midPoint runs into a problem, it can often correct the problem by itself.

Individual mechanisms differ in a way data inconsistency is discovered: livesync will actively look for new changes, reconciliation will compare the data one-by-one and opportunistic synchronization will discover inconsistency by pure chance.
But all the mechanism react to inconsistency in the same way.
There is only one policy that specifies how to fix the system.
Of course, there may be slight deviations in the behavior.
For example, we usually want _import_ to behave in slightly different way than _reconciliation_.
And midPoint allows that.
But overall, there is just one big synchronization mechanism.
And this has a good reason.
It does not really matter how the problem was discovered.
What really matters is that the problem gets fixed.
We do not want to maintain four separate configurations for that.
Having one policy is enough.
MidPoint knows which part of the configuration need to be applied in each specific situation.
And it does it automatically.
This unifying approach significantly simplifies the configuration of midPoint synchronization mechanisms.
And that is also a reason why the boundaries of individual synchronization mechanisms are quite fuzzy.
In fact this is just a single big mechanism with several facets.

== Sources, Targets And Other Creatures

The tale of idealistic identity management deployment starts with a human resources (HR) system.
The HR system is supposed to have records for all the identities therefore it is _authoritative source_ resource.
Identity management system pulls in all the data from HR, recomputes them and creates accounts on _target resources_.
And they lived happily ever after.

Now, let’s get back to reality.
The HR resource is indeed an authoritative source of data in many real-world cases.
But it is a limited source.
It contains only data about employees.
And it has only partial information.
For example there is no username.
Username has to be generated by IDM logic.
There is no initial password.
Organizational structure assignment is often incomplete, missing or unreliable.
Therefore it is only a _partially-authoritative source_.
There may be additional authoritative sources for contractors, partners, suppliers, support engineers and other identities that need to access our systems.
These are _additional source systems_.
Then there is a directory system which is often Active Directory.
This should be a _target resource_ in theory.
But there usually there are pieces of authoritative information in here.
For example an algorithm to generate a username may be based on the usernames that are already taken in the Active Directory.
The active directory may also be needed to create an e-mail address.
Directory systems are also used as a semi-authoritative sources for telephone numbers, office numbers and so on.
Therefore such resource are both _target_ and _source_ resources.
And then there are finally target resources.
These are not authoritative in any way.
Identity management system will only write to these.
Or ... will it?
What happens when a conflicting account already exists on such resource and therefore we cannot create a new account for a new employee.
And how do we check if there are no accounts that are not supposed to be there?
It turns out that even the target systems contain valuable information after all.

The reality brings a wild mix of source, target, semi-source, target/source and quasi-target resources that are almost impossible to put into a pre-defined boxes.
Therefore midPoint does not bother to define a concept of "source" or "target" resource.
All resources can be both sources and targets and the authoritativeness of each attribute can be controlled on a very fine level.
Almost every real-world situation can easily fit into this model.

== Inbound and Outbound Mappings

MidPoint is firmly based on the principle of reuse.
Previous chapter explained that behavior of attributes during provisioning is controlled by _mappings_.
Therefore, it is perhaps no big surprise that the behavior of attributes during synchronization is also controlled by mappings.
In fact, provisioning is just a special case of synchronization.
Following picture explains the combined mechanism.

image::05-01-sync-source-target.png[Synchronization]

There are two types of mappings:

* *Inbound mappings* map data _into_ midPoint.
These mappings take the data from the source resources, transform them and apply the result to the user object.

* *Outbound mappings* map data _out of_ midPoint.
These mappings take user properties, transform them and apply the result to account attributes in target systems.

The mappings themselves are almost the same regardless whether they are inbound or outbound.
They have sources, targets, expressions, conditions, etc.
Just the sources and targets are reversed:

[cols="h,1,1"]
|===
| |Inbound mapping |Outbound mapping

|Direction
|resource → midPoint
|midPoint → resource

|Mapping source
|resource object (e.g. account)
|focal object (e.g. user)

|Mapping target
|focal object (e.g. user)
|resource object (e.g. account)
|===

That is it.
Just think about the same mappings that were used in previous chapter, just flip the direction.
Now the mapping will take data from the account and the results will be applied to user object.
Like this:

[source,xml]
----
<attribute>
    <ref>ri:lastname</ref>
    <inbound>
        <target>
            <path>$focus/familyName</path>
        </target>
    </inbound>
</attribute>
----

This mapping will take the value of `lastname` attribute from the resource and store the value in `familyName` property of midPoint user.

The rest is the same as outbound mappings.
All the expressions and evaluators can be used for inbound mappings in the same way as for outbound mappings.
For example a Groovy expression can be used to sanitize the value before it is stored in midPoint:

[source,xml]
----
<attribute>
    <ref>ri:lastname</ref>
    <inbound>
        <expression>
            <script>
                <code>lastname?.trim()</code>
            </script>
        </expression>
        <target>
            <path>$focus/familyName</path>
        </target>
    </inbound>
</attribute>
----

The same approach can also be taken for activation and even for password mappings.
However, there is one difference for password mappings.
Password are usually write-only value.
When the password is written it is usually hashed and the original value cannot be retrieved any longer.
Then there are resource such as HR systems that do not store employee passwords at all because those are not really accounts that we are reading.
Those are just regular database entries that the connector presents as accounts.
Inbound password synchronization is almost never easy and it often requires a lot of planning and ingenuity.
However, there is one method that is used quite often.
The initial user passwords are usually randomly generated.
As this is a very common case midPoint can do this easily:

[source,xml]
----
<credentials>
    <password>
        <inbound>
            <strength>weak</strength>
            <expression>
                <generate/>
            </expression>
        </inbound>
    </password>
</credentials>
----

This mapping generates random password for a user.
Both the mapping and the `generate` expression evaluators are quite smart.
The mapping knows that the target is user password without any need to explicitly specify that.
In addition to that the generate expression evaluator will take user password policy into consideration.
It does not make sense to generate any random password.
If we do not consider password policy then we can generate password that is too short, too long, too weak to pass the policy or too strong to be useful in any way.
Therefore the `generate` expression will look for password policy and generate a random password that just matches the specified password policy.

There are more important details to see here.
The inbound password mapping is _weak_.
And there is good reason for this.
We do not want midPoint password to be replaced by randomly generated password.
We only want to set a random password in case that it is an initial password, the first and only password.
And that is exactly what a weak mapping does: it sets new value only if the target does not have any existing value.
Therefore this mapping will not overwrite passwords that are already set.

NOTE: There is no direct account-account synchronization in midPoint.
As explained before, midPoint follows a star topology (a.k.a. "hub and spoke").
Therefore the synchronization is either from account to user (inbound) or from user to account (outbound).
The effect of account-account synchronization is achieved by combing inbound and outbound synchronization mechanisms.

== Correlation

It is all quite easy to import all HR records into an empty midPoint.
Set up inbound mappings, start import task, wait a bit and all is done.
But practical situations are much more complex.
Synchronization algorithm usually do not run on a green field.
Live synchronization and reconciliation are supposed to work with pre-existing midPoint users.
And import is usually not trivial either, for example in cases when we try to import data from an additional data source into a running midPoint deployment.
Some users in the import set are new, but there may be accounts for existing users.
We need to tell the difference between brand new account and an account that belongs to an existing user.
We need to handle those situations in a different way.
Of course, midPoint has an easy solution for this: correlation mechanism.

Correlation expression is a method how to connect newly-discovered accounts and existing users.
It works like this: whenever midPoint discovers new account it will try to link that account to an existing user.
Correlation expression is used to do this.
Correlation expression is in fact a parametric search query.
Such search query is constructed for every new account and it is used to look for users that the account belongs to.
The easiest form of the correlation expression is to look by using an identifier:

[source,xml]
----
<correlation>
    <q:equal>
        <q:path>employeeNumber</q:path>
        <expression>
            <path>$projection/attributes/empno</path>
        </expression>
    </q:equal>
</correlation>
----

This correlation query takes the value of `empno` attribute of the account.
This value is placed into the search query that midPoint computes in memory.
Given an account with empno attribute set to `007`, the resulting search filter looks like this:

[source,xml]
----
    <q:equal>
        <q:path>employeeNumber</q:path>
        <q:value>007</q:value>
    </q:equal>
----

MidPoint looks for users that match this search filter.
If there is a user with `employeeNumber` property set to `007` then such user is considered to be an owner of the account.

MidPoint has its own data representation mechanism and object structure.
Therefore midPoint also has its own query language that is designed to work with the object structure.
The query language is not difficult to learn as it follows the structure of other common query languages.
The language itself is described later in the book and in midPoint documentation.
But do not worry about this too much now.
Vast majority of correlation expressions is very simple.
In fact it is usually just a single `equal` clause just like that one used in the example above.

Using search queries for correlation may seem a little bit too complex.
But it is necessary.
The correlation expression must be a search filter because that is the only efficient way how to find single user in a large set of other users.
We cannot scan the accounts one-by-one.
We need to utilize the search power of the database for this.

== Synchronization Situations and Reactions

Correlation expression can be used to find an owner for a new account.
That is a part of the solution but not entire solution.
If the owner is found then the action is quite obvious: link the account to the user and proceed as usual.
But what to do if the owner is not found?
This resource may be an authoritative resource and therefore we want to create a new user based on the account.
Or this may be a reconciliation with a target resource and in that case this means that we have found an illegal account.
We probably want to disable such account.
And what to do if more than one owner is found?
This can all become quite complicated.
Therefore midPoint has a concept of _synchronization situations_ to make it understandable and manageable.

Whenever midPoint deals with a change on an account, the _situation_ of that account is determined.
The situation reflects whether this account is already linked to the user, whether we know the candidate owner, but it is not linked yet, whether we cannot determine the owner and so on.
Individual situations are explained in the following table.

|===
|Situation |Description

|`linked`
|The account is properly linked to the owner.
This is the normal situation.

|`unlinked`
|The account is not linked to the owner, but we know who the owner is.
Correlation expression told us who the owner is.
In this case midPoint thinks that the link should exist, but it is not linked yet.

|`unmatched`
|The account is not linked and we do not even know who the owner is.
The correlation expression has not returned any candidates.

|`disputed`
|The account is not linked, but there are more potential owners.
The correlation expression returned more than one candidate.

|`collision`
|The account is linked to more than one owner.
This should not happen under normal circumstances.
This is usually caused by faulty customizations or software bugs.

|`deleted`
|There was an existing account but it was deleted on the resource.
|===

After synchronization _situation_ is determined, midPoint continues by figuring out what a proper _reaction_ is.
The reaction is quite clear for some situations (e.g. `unlinked`), but there is a lot of variability for other situations (e.g. `unmatched`).
This variability is a reason that midPoint allows to set a reaction for each situation individually.
There are several pre-defined reactions:

|===
|Action |Description

|Add focus
|New midPoint user will be created and it will linked to the account.
This is usually a reaction configured for authoritative resources, used in situation when a new account is discovered.

|Delete focus
|MidPoint user that owns the account will be deleted.
This is usually a reaction configured for authoritative resources, used in situations when midPoint detects that an account was deleted.

|Inactivate focus
|MidPoint user that owns the account will be disabled.
This is also used for authoritative resources.
But this is a milder reaction.

|Link
|The user-account link will be created.

|Unlink
|The user-account link will be removed.
The account will no longer be linked to the user.

|Delete shadow
|The account will be deleted.
This is the usual reaction when illegal account is detected on non-authoritative resource.

|Inactivate shadow
|The account will be disabled.
Usually a milder reaction to an illegal account.
|===

If no reaction is explicitly configured for a situation then midPoint does nothing.
Just the situation is recorded in midPoint repository.
This is part of midPoint philosophy not to change the data unless an action was explicitly configured.

The reactions can be defined in the synchronization section of resource configuration:

[source,xml]
----
<synchronization>
    <objectSynchronization>
        <correlation>...</correlation>
        <reaction>
            <situation>linked</situation>
            <synchronize>true</synchronize>
        </reaction>
        <reaction>
            <situation>deleted</situation>
            <action>
                <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/action-3#deleteFocus</handlerUri>
            </action>
        </reaction>
        <reaction>
            <situation>unlinked</situation>
            <action>
                <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/action-3#link</handlerUri>
            </action>
        </reaction>
        <reaction>
            <situation>unmatched</situation>
            <action>
                <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/action-3#addFocus</handlerUri>
            </action>
        </reaction>
    </objectSynchronization>
</synchronization>
----

Most of the configuration is perhaps self-explanatory.
This is a typical authoritative resource.
If there is a new account on the resource and we do not have an owner (situation: `unmatched`) then create a new user (action: `addFocus`).
If the account is deleted from the resource (situation: `deleted`) then delete the user as well (action: `deleteFocus`).
If we happen to find an account which should be linked but it is not (situation: unlinked) then link it (action: `link`).
The only think that deserves an explanation is the reaction to linked situation.
In this case there is not much to do.
Everything seems to be in order.
However there may still be attributes that are not set correctly.
Remember the inbound mappings?
The inbound mappings were not even mentioned in this section yet.
And for a good reason.
The inbound mappings are not evaluated at this stage.
Evaluation of inbound mappings happen only after the situations and reactions are evaluated.
We need this so all the accounts are properly linked (or unlinked) and the inbound mappings have valid sources and targets.
But the evaluation of inbound and outbound mappings do not happen by themselves.
MidPoint does not change the data unless it is explicitly configured to.
There are reactions for `unmatched`, `deleted` and `unlinked` situations.
Therefore in those cases midPoint assumes that it is expected to fully synchronize everything and therefore all the mappings and policies are evaluated automatically.
But there is no reaction for `linked` situation.
In that case midPoint assumes that it should do nothing as nothing is explicitly configured.
Hence the `synchronize` property.
This property can be used to force midPoint to do full synchronization even if there is no explicit action configured.
And it can also be used to avoid full synchronization even if explicit action is configured.

image::05-02-synchronization-flow.png[Synchronization flow]

The figure above illustrates the usual sequence of events during inbound synchronization:

. Account is stored in the resource database.

. Appropriate identity connector is used to read the account.

. Account shadow is created in midPoint.

. Correlation expression is evaluated to determine account ownership (if the account is not already linked to a user).

. Synchronization situation is determined based on account ownership and state of the account.

. Appropriate reaction to the situation is determined based on resource configuration.

. Inbound mappings are evaluated to map account values to the user.

Please note that the description of this process is slightly simplified for clarity.
There are also obvious deviations from this process. E.g. inbound mappings are skipped in case that the user is about to be deleted, the mappings are also skipped if the reaction does not include “synchronization” and so on.
But generally this is what usually happens during inbound synchronization.

NOTE: MidPoint is an extensible system.
There are several prefabricated synchronization reactions described above.
Those reactions can handle the vast majority of situations that happen during synchronization.
However, there is a possibility to extend the system with completely custom reactions.
MidPoint was designed for this.
This is the theory.
However, currently this part of midPoint is only partially extensible.
Full extensibility feature was planned, but it was never implemented.
Therefore extensibility of synchronization reaction is possible, but it might be quite hard to achieve this in practice and it may require significant development effort.
But there is another way.
MidPoint development team would absolutely love to finish this extensibility feature as it was originally planned.
However, existing midPoint customers had so far prioritized other features.
MidPoint subscribers and sponsors are funding the development therefore midPoint development must follow their priorities.
Therefore if you are interested in full synchronization reaction extensibility (or any other feature) please consider purchasing midPoint subscription or sponsoring the feature.

== Synchronization Tasks

Now we know how the inbound synchronization works: midPoint reads the account, then correlation is applied, situation determined and reaction executed.
However, we have not yet discussed the details of the very first step: how does midPoint actually read the account?
Nothing happens without a reason, therefore there must be some active component in midPoint that actually looks for the new, changed and deleted accounts.
And that component is a _synchronization task_.

MidPoint _task_ is an active process that is running inside midPoint server.
This is the first time that we encountered the concept of a _task_, but it is definitely not the last one.
Tasks are used for many purposes in midPoint.
They are used to track long-running operations, approvals and actions that work on large sets of objects (bulk actions).
There are tasks that execute cleanup jobs, compile reports and provide variety of other functions.
The concept of tasks is a very powerful and flexible one.
Tasks can be used to track execution of a short one-off operations.
Tasks can be used to execute scheduled actions in regular intervals.
Or tasks can be used to track long-running processes.
We will be using tasks in almost every chapter of this book.

Tasks are used as an active component to "run" almost all synchronization mechanisms:

* *Reconciliation task* is listing all the accounts from a specific resource.
The task executes reconciliation process for every account that is found.
This means that midPoint computes how that particular account should look like and then the computed values are compared with real account attributes.
This task is usually scheduled for regular execution using quite a long execution interval (days or weeks).

* *Live synchronization task* is looking (polling) for changes in a specific resource.
The task will look for created, modified and deleted accounts.
The task will get a description of the change and pass that to midPoint synchronization mechanisms.
This task is almost always scheduled for regular execution and the execution interval is very short (minutes or seconds).

* *Import from resource task* is listing all the accounts from a specific resource.
The task will pretend that the accounts were just created.
This usually motivates midPoint to create users based on those accounts or link these accounts to existing users.
This task is usually not scheduled and it is almost always executed manually.

Each type of synchronization task is detecting changes using a different mechanism.
However, once the task detects the change or reads the account then the processing is the same for all tasks.
All the tasks lead to the same algorithms based on the same configuration and policies.
Therefore it does not matter whether it has all started in reconciliation or live synchronization task.
It will all end up in the same correlation-situation-reaction-mapping process.

However, the tasks are necessary to initiate the synchronization.
They are the active part, the spark that starts the synchronization process.
Without the tasks the synchronization does not really work.
There are ways how the synchronization can "happen" even without a task, e.g. as a reaction to user interface operation or if a new account is discovered during an unrelated operation.
But practical deployments need at least one synchronization task to work properly.
This task takes care of the vast majority of synchronization cases.

Strictly speaking tasks are quite a strange kind of animal.
Tasks have their data and configuration as most other midPoint objects.
But tasks are active.
Therefore there are CPU threads associated with the tasks when the tasks are running.
There are mechanisms how to monitor task progress.
The tasks need to be cluster-aware so they can fail over to a different midPoint node if one node fails.
The tasks are quite rich and a bit tricky to handle.
But midPoint is making task handling reasonably simple.
Tasks are represented as ordinary midPoint objects.
Therefore they can be imported to midPoint in XML/JSON/YAML form as any other object.
Tasks can be easily edited in their XML/JSON/YAML form to change the scheduling, modify the parameters and so on.
Of course, there are some special functions that only the tasks have (such as suspend and resume) that cannot be controlled using the XML/JSON/YAML format.
But the vast majority of task management can be done using the very same methods that are used to control other midPoint objects.

Tasks can be created by taking the XML and importing that to midPoint.
And that’s the way how synchronization tasks are often managed.
When an XML-formatted resource definition is created then there is often an associated synchronization task.
Which means that both resource and all the necessary synchronization tasks can be imported together.
Synchronization tasks can also be created from midPoint user interface.
They are usually created by using special-purpose buttons in resource detail pages.

image::05-03-synchronization-tasks.png[Synchronization tasks]

Once the synchronization tasks are created they can be managed in the same way as other tasks are managed: in the _Server tasks_ part of the midPoint user interface.

== Synchronization Example: HR Feed

This section describes complete working example that feeds HR data into midPoint.
The ExAmPLE company HR system is an old and complex system.
Therefore the easiest integration method is to use structured text exports.
The HR system is set up to export the employee data to a comma-separated text file (CSV) every night.
MidPoint takes this export file and updates the data about users.

This configuration is done in three steps.
First we will use a simple setup to import the data into midPoint.
This is an operation that is executed only once.
Then the configuration will be updated to run scheduled reconciliation task.
Reconciliation compares all the data records every time and it makes any necessary updates.
Even though this method would be perfectly acceptable for the company of this size, we still set up a live synchronization task.

The core of the configuration is contained in a single resource definition file.
Following paragraphs explain individual parts of the file.
There are few additional configuration files for reconciliation and live synchronization tasks.
Simplified XML notation is used for clarity.
The complete file in a form that is directly usable in midPoint can be found at the same place as all the other samples in this book (see <<92-additional-information.adoc#92-additional-information,Additional Information>> chapter for details).

This HR resource is a data source.
It will be used to "pull" the data inside midPoint.
However, as we have described previously, there is no fundamental difference between source and target resources in midPoint.
Therefore this HR resource starts in entirely ordinary way.
There is a reference to the CSV connector and the connector configuration:

[source,xml]
----
<resource oid="03c3ceea-78e2-11e6-954d-dfdfa9ace0cf">
    <name>HR System</name>
    <connectorRef>...</connectorRef>
    <connectorConfiguration>
        <configurationProperties>
            <filePath>/var/opt/midpoint/resources/hr.csv</filePath>
            <encoding>utf-8</encoding>
            <fieldDelimiter>,</fieldDelimiter>
            <multivalueDelimiter>;</multivalueDelimiter>
            <uniqueAttribute>empno</uniqueAttribute>
            <passwordAttribute>password</passwordAttribute>
        </configurationProperties>
    </connectorConfiguration>
    ...
----

The next section is schema handling configuration.
That is where is becomes slightly more interesting.
The schema handling section contains inbound mappings for HR account attributes:

[source,xml]
----
    ...
    <schemaHandling>
        <objectType>
            <objectClass>ri:AccountObjectClass</objectClass>
            <attribute>
                <ref>ri:empno</ref>
                <inbound>
                    <target>
                        <path>$focus/name</path>
                    </target>
                </inbound>
                <inbound>
                    <target>
                        <path>$focus/employeeNumber</path>
                    </target>
                </inbound>
            </attribute>
            <attribute>
                <ref>ri:firstname</ref>
                <inbound>
                    <target>
                        <path>$focus/givenName</path>
                    </target>
                </inbound>
            </attribute>
            <attribute>
                <ref>ri:lastname</ref>
                <inbound>
                    <target>
                        <path>$focus/familyName</path>
                    </target>
                </inbound>
            </attribute>
            ...
----

The account attribute `empno` is mapped to midPoint user properties name and `employeeNumber`.
Account attributes `firstname` and `lastname` are mapped to `givenName` and `familyName` properties respectively.
This is perhaps self-explanatory.

The next part of the configuration specifies mappings for activation and credentials:

[source,xml]
----
            ...
            <activation>
                <administrativeStatus>
                    <inbound/>
                </administrativeStatus>
            </activation>

            <credentials>
                <password>
                    <inbound>
                        <strength>weak</strength>
                        <expression>
                            <generate/>
                        </expression>
                    </inbound>
                </password>
            </credentials>
            ...
----

The activation mapping is very simple.
Activation is a very specific concept in midPoint.
MidPoint knows activation attributes and their meaning.
Therefore there is no need to specify a lot of details.
The activation mapping simply specifies that the administrative status should be mapped in the inbound direction.
And that is it.

However the mapping for credentials needs a bit of explanation.
What midPoint sees as HR accounts are not exactly accounts.
They are usually just records in the HR database.
Nobody is using these HR records to log into the HR systems.
Therefore there is no password associated with them.
But we need a password for the users in midPoint.
Therefore we are going to generate them.
And for that we are going to use the weak mapping with generate expression that was explained above.

The mappings are undoubtedly important.
The mappings specify how are the account data reflected to midPoint user.
But the mappings do not specify whether the accounts should be created or deleted.
Mappings control the data, but they do not control the _lifecycle_.
It is the next configuration section that makes this resource really authoritative:

[source,xml]
----
    ...
    <synchronization>
        <objectSynchronization>
            <enabled>true</enabled>
            <correlation>
                <q:equal>
                    <q:path>employeeNumber</q:path>
                    <expression>
                        <path>$projection/attributes/empno</path>
                    </expression>
                </q:equal>
            </correlation>
            <reaction>
                <situation>linked</situation>
                <synchronize>true</synchronize>
            </reaction>
            <reaction>
                <situation>deleted</situation>
                <synchronize>true</synchronize>
                <action>
                    <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/action-3#deleteFocus</handlerUri>
                </action>
            </reaction>
            <reaction>
                <situation>unlinked</situation>
                <synchronize>true</synchronize>
                <action>
                    <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/action-3#link</handlerUri>
                </action>
            </reaction>
            <reaction>
                <situation>unmatched</situation>
                <synchronize>true</synchronize>
                <action>
                    <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/action-3#addFocus</handlerUri>
                </action>
            </reaction>
        </objectSynchronization>
    </synchronization>
    ...
----

Given the information in this chapter this configuration should be quite easy to read.
This is how a typical authoritative resource works.
If there is a new account on the resource and we do not have an owner (situation: `unmatched`) then we create a new user (action: `addFocus`).
If there is a new account for which we can find existing owner (situation: `unlinked`) then simply link it (reaction: `link`).
If the account is linked already (situation: `linked`) then we just synchronize the data.
In fact, we will synchronize data for all the other situations as well.
Except the last one.
If the account is deleted in the HR system (situation: `deleted`) then we want to delete midPoint user as well (reaction: `deleteFocus`).
As the user gets deleted there is no point in synchronizing the data.
MidPoint knows that and skips application of mappings.

The ownership of the accounts that are not already linked is determined by the correlation expression.
In this case the expression will be comparing account attribute `empno` with user property `employeeNumber`.
If the values match then the user is considered to be an owner of the account.

There is one more detail in this resource that we have skipped:

[source,xml]
----
    ...
    <projection>
        <assignmentPolicyEnforcement>none</assignmentPolicyEnforcement>
    </projection>
    ...
----

This is a setting that adjusts the behavior of midPoint _assignments_.
As was already mentioned, all resources in midPoint are created equal.
The source resources must follow the same rules as target resources.
And one of the fundamental rules of midPoint is that there should not be any account without a specific reason to exist.
In midPoint terminology every account exists because there is an _assignment_ that justifies its existence.
While this approach is exactly what we want for the vast majority of (well behaving) resources, it is not exactly ideal for source resources.
Those resources work the other way around.
The HR account is in fact a cause for midPoint user existence, not its effect.
Therefore there is really useful `assignmentPolicyEnforcement` setting that controls the behavior of assignments.
This setting is used in a variety of scenarios, mostly for data migration and to tame resources that just won’t behave in a civilized manner.
But in this case the setting is used to turn off the assignment enforcement for this resource entirely.
As this resource is an authoritative source the assignment enforcement does not make much sense.
Behavior of this resource is defined by the `synchronization` section of resource configuration.

Resource configuration is complete now.
This configuration sets up the connector, mappings and synchronization policies.
This configuration is the same for all the synchronization flavors: import, reconciliation and live sync - they will all use the same settings.
When it comes to configuration, the only difference between those synchronization flavors is the way how the synchronization tasks are set up.
If an import task is set up then import of resource accounts will be executed.
If reconciliation task is set up, the reconciliation will be executed.
It is all in the tasks.
And synchronization tasks can be easily set up using those convenient buttons in the user interface.
But we like to make our lives a bit painful in our part of the world.
Therefore we are going to go hardcore and we import the tasks in the XML form.

First task is an import task.
This task lists all the accounts in the HR CSV file.
The task pretends that each of the accounts was just created.
If the task is executed for the first time then resulting situation of the accounts is going to be either `unmatched` or `unlinked`.
Therefore the task creates new midPoint users or links the accounts to existing users.

[source,xml]
----
<task oid="7c57adc2-a857-11e7-83ac-0f212d965f5b">
    <name>HR Import</name>
    <taskIdentifier>7c57adc2-a857-11e7-83ac-0f212d965f5b</taskIdentifier>
    <ownerRef oid="00000000-0000-0000-0000-000000000002"/>
    <executionStatus>runnable</executionStatus>
    <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/synchronization/task/import/handler-3</handlerUri>
    <objectRef oid="03c3ceea-78e2-11e6-954d-dfdfa9ace0cf" type="c:ResourceType"/>
    <recurrence>single</recurrence>
</task>
----

This is a very basic structure of the task.
Similarly to all midPoint objects a task has a name.
Then there is a task identifier which is used for internal task management purposes.
This is usually the same as task object OID. Task needs definition of an owner.
The owner is a user that is executing the task.
This is important, because authorizations of task owner determine what the task is allowed to do.
This is also the identity that will be recorded in the audit log.
In this case `administrator` is owner of this task.
Task execution status tells whether the task is running, it is suspended or finished.
Then there is a handler URI. The handler URI specifies what the task really does.
It (indirectly) refers to the code that the server executes.
In this case the task URI specifies that this is a synchronization task that imports accounts from the resource.
And the resource is specified by the objectRef reference.
This points to our HR resource.
The last item is recurrence.
Recurrence specifies whether the task runs only once (single) or whether the execution should be repeated (recurring).

When this XML definition is imported to midPoint, the server tries to execute the task.
That means that import of accounts from the HR resource starts immediately.
Progress of the task can be monitored in the Server tasks section of midPoint user interface.
The import task is not a recurring task.
Therefore it will run only once.
If you need to re-run the task, you can do that from midPoint user interface.
But the task will not be executed unless you explicitly tell midPoint to do so.
This is how typical import tasks work.
They are usually executed when a new resource is connected to the system.
And once everything is set up, correlated and linked then the import task is not needed any more.

A clever reader may ask what happens when the import task is executed more than once.
The answer is simple: not much.
Even if the task pretends that the accounts were just created, midPoint is not fooled easily.
In fact, it is hard to believe that the account was just created if midPoint already has shadow for that account and it is linked to a user, isn’t it?
Therefore midPoint is going to stay calm and carry on.
If there is any change in the account attribute, the change will be reflected to the user.
But that is it.
No big drama here.

Import task will get the data from the resource into midPoint.
But as import is not a recurring task it will not keep the data synchronized.
Import tasks are not designed to do so.
But there are other tasks that are designed for continuous synchronization.
Reconciliation task is one of these.
Reconciliation task lists all the accounts on a resource and compares that with data in midPoint.

[source,xml]
----
<task oid="bbe4ceac-a85c-11e7-a49f-0f5777d22906">
    <name>HR Reconciliation</name>
    <taskIdentifier>bbe4ceac-a85c-11e7-a49f-0f5777d22906</taskIdentifier>
    <ownerRef oid="00000000-0000-0000-0000-000000000002"/>
    <executionStatus>runnable</executionStatus>
    <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/synchronization/task/reconciliation/handler-3</handlerUri>
    <objectRef oid="03c3ceea-78e2-11e6-954d-dfdfa9ace0cf" type="c:ResourceType"/>
    <recurrence>recurring</recurrence>
    <schedule>
        <cronLikePattern>0 0 1 ? * SAT</cronLikePattern>
        <misfireAction>executeImmediately</misfireAction>
   </schedule>
</task>
----

Definition of a reconciliation task is almost the same as the definition of import task.
But there are crucial differences.
First of all there is different handler URI. This is what makes this task a reconciliation task.
Then the task is recurring.
This means that midPoint will repeat execution of the task.
Therefore there is also execution schedule so the server knows when to execute the task.
Reconciliation tasks are usually resource-intensive therefore we usually want to execute them at a very specific off-peak times.
For that reason the execution schedule is defined using a cron-like pattern.
UNIX-friendly readers will be surely familiar with this.
The format is:

`_seconds_ _minutes_ _hours_ _day-of-month_ _month_ _day-of-week_ _year_`

Therefore this task will be executed every Saturday at 01:00:00am.
There is also definition of misfire action.
Misfire is a situation when the server is down at the time when the task is supposed to run.
Therefore if the server is down in the early hours of Saturday this task will be executed as soon as the server starts up.

Reconciliation task is a real workhorse of identity management.
It can be used in almost any resource.
It is very reliable.
It is often used to fix many problems, apply new policies, look for missing accounts, illegal accounts and so on.
It is indeed a really useful tool.
But it has its downside.
Reconciliation iterates through all the accounts, it recomputes all the applicable policies for every account, one-by-one.
Therefore it may be quite resource-intensive.
It m may be even quite brutal if the policies are complex, user population is high and the resources are slow.
This can take hours or even days in extreme cases.
But even for smaller deployments reconciliation is not entirely easy.
The problem is not in midPoint.
MidPoint can be usually scaled up to handle the load.
But listing all the accounts often may put unacceptable load on the resources.
Therefore reconciliation is not executed often.
Daily, weekly or even monthly reconciliation seems to be a common approach.
Reconciliation is reliable, but it is not entirely what we would call "real-time".
But of course, midPoint has a faster alternative.

_Live synchronization_ is the way to go for real-time synchronization.
Or rather almost real-time synchronization.
Practical latencies for live synchronization are in the range of seconds or minutes, which is fast enough for most practical cases.
Live synchronization is also quite resource-efficient.
Overall it is much faster and much lighter than reconciliation.
But live synchronization is not available for all resources.
Live synchronization depends on the ability to get recent changes from the resource in a very efficient way.
Therefore it is only available for resources that record the changes.
The specific mechanism to record the changes may vary from resource to resource.
It may be as basic as a simple modification timestamp or it may be a complex change log.
But it has to be good enough for the connector to discover recent changes and it must be efficient enough for the connector to do that every couple of seconds.
If such mechanism is available and the connector knows how to use it then setting up live synchronization is easy.
All that is needed is synchronization task.

[source,xml]
----
<task oid="7c57adc2-a857-11e7-83ac-0f212d965f5b">
    <name>HR Live Synchronization</name>
    <extension>
        <mext:kind>account</mext:kind>
    </extension>
    <taskIdentifier>7c57adc2-a857-11e7-83ac-0f212d965f5b</taskIdentifier>
    <ownerRef oid="00000000-0000-0000-0000-000000000002"/>
    <executionStatus>runnable</executionStatus>
    <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/synchronization/task/live-sync/handler-3</handlerUri>
    <objectRef oid="03c3ceea-78e2-11e6-954d-dfdfa9ace0cf" type="c:ResourceType"/>
    <recurrence>recurring</recurrence>
    <schedule>
        <interval>10</interval>
    </schedule>
</task>
----

This task definition should be easy to understand now.
There is a different handler URI that makes this a live synchronization task.
There is also a different type of scheduling.
We do not want to execute this task at a specific time.
We rather want to execute it all the time at regular intervals.
In this case the interval is set to 10 seconds.
And that is all that is needed to have live synchronization running.
If the HR CSV file is changed now, the changes will get automatically processed by midPoint.

Setting up configuration flavors is just a matter of setting up the tasks.
The rest of the configuration is the same for all flavors.
Therefore it is very easy to run both live synchronization and reconciliation for the same resource.
Just create two tasks.
This is quite a common setup.
Live synchronization is used to get the changes quickly and efficiently.
And reconciliation is used to make sure all the changes were processed and that the policies are applied consistently.

That is all.
Now we have the HR feed up and running.
However, there are still few issues.
A clever reader would surely notice that this is not a very good HR resource.
MidPoint users created from this HR feed have given name and family name, but the full name field is empty.
But do not worry.
We will sort that out in later chapters with the help of _object template_.
Also the users have employee number as their username.
This may be in fact a very good approach for some deployments as it avoids the need to rename accounts.
However, it is not a very user-friendly approach.
Therefore most deployments need to generate more convenient usernames.
This is easy to do with midPoint and we will also address that later.
There is still a lot of things to learn before we get to a complete synchronization set up.

== HR Feed Recommendations

All resources are created equal in midPoint.
However, source resources almost always have slightly special standing.
Even though midPoint mechanisms are the same for all resources, the data coming from the sources often have significant impact on the entire solution.
There is this traditional computer engineering wisdom: _garbage in, garbage out_.
An error in data feed may cause a lot of problems everywhere.
Therefore it is important to get the data sources right.
And this is usually one of the first steps in an IDM project.

Unfortunately, source data feed is usually quite difficult to set up correctly.
And it is almost impossible to get it right at the first try.
Therefore setup of a data source is usually an iterative process.
And there may be many iterations - especially if the quality of the source data is unknown.
The process usually goes like this:

. Set up initial source resource definition based on the information you have.
Set up connector and test connection.
Check that you can see the accounts.
Set up mappings and synchronization policy.

. Test the import process on a couple of individual accounts.
Navigate to the resource details pages, click on Accounts tab to list accounts, choose an account and click on the small _Import_ button in the table row.
Import of that individual account will start.
Just that one account.
It is easier to see the errors (see step 6) by using this method.

. Fix any errors that you see and repeat step 2.

. Create an import task and run import of all accounts.

. Examine task errors.
You can use task details page to get the summary.

. If there are no errors, then examine the users.
If everything is OK then congratulations.
You have a good import.
However, this is unlikely to happen on the first few attempts.

. You will probably need to have a look into system logs to learn the details of individual import failures.
MidPoint heavily relies on logs for detailed error analysis.
See the <<90-troubleshooting.adoc#90-troubleshooting,Troubleshooting>> chapter of this book to learn how to adjust log levels and how to get understand the log messages.

. Some errors are likely to be caused by the errors in your mappings and policies.
Those are usually easy to fix.
But there are usually worse errors as well – errors caused by wrong or unexpected input data.
The right way would be to fix the data.
But that is not always possible (in fact it is almost never a feasible option).
Fortunately, most of the input data errors can be fixed (read: "worked around") in midPoint with a bit of ingenuity.
Just use the power of the mappings.

. Rinse and repeat.
If the errors you get are not severe then you may simply re-run the import task.
This often works just fine.
But if the problem was in a mapping that completely ruined all the data then it is perhaps best to start with a blank slate.
We are all just humans and this situation happens quite often, especially in the beginning while you are still learning.
Therefore there is a special feature to help you out.
Navigate to _Configuration > Repository Objects_.
There is a small unassuming expand button in the top-right part of the screen.
That button opens a context menu.
Select “Delete all identities” item.
That is what we lovingly call “laxative button”.
A brief dialog will pop up asking you to specify which identities exactly are to be deleted (users, shadows, …).
This is a very convenient way how to get back to a black slate, but keep all the configuration (resources, templates, tasks).

. Goto step 2. Repeat until done.

If the initial IDM deployment step includes an HR feed we strongly recommend to start with that HR feed.
It is significant benefit to have authoritative HR data in the midPoint to start with.
It is usually easier to correlate other resources to midPoint users later on, if the users were created from a reasonably reliable HR data.
Also, it will usually take some tweaking to get the HR import right.
The possibility to easily clean up midPoint and get to a clean slate is extremely useful.
But that is possible only if the HR feed is the first resource that is connected to midPoint.

A clever reader would notice, that we assumed that the source feed will be taken from a CSV file.
And this is indeed the case in majority of cases.
If a new employee or contractor is about to join the company there is usually no hurry.
This information is entered into the HR system at least a few days in advance therefore daily CSV export is perfectly acceptable.
However, there may be cases when we want a faster response.
Or maybe we do not want additional burden of dealing with CSV exports.
Of course, there is a solution.
In theory any connector can be used for source resource.
There are specialized connectors that are taking data directly from the HR system.
For example there is a connector for Oracle HCM system.
Unfortunately, there is no connector that can take data from SAP HR system yet.

== Synchronization and Provisioning

Synchronization and provisioning are intimately connected.
Everything that we have explained about provisioning in the previous chapter also applies to synchronization.
In fact provisioning and synchronization are just applications of the same basic mechanisms.
Provisioning starts with modification of a user.
Synchronization starts a bit earlier: inbound mappings are used to map values from source system to the user.
The result of inbound mapping evaluation is that the user object is modified.
According to midPoint principles it does not matter how the user was modified.
The reaction is the same: accounts are provisioned, modified or deleted as needed.

The synchronization (_inbound_ processing) and provisioning (_outbound_ processing) usually happen in the same seamless operation.
For example the HR connector detects update in the last name of an employee.
That modification is applied to midPoint user, therefore the family name of midPoint user is updated.
The operation continues by evaluating all templates, roles and outbound mappings.
The outbound mappings usually map the family name change to the resource attributes.
Therefore the resource accounts linked to the user are immediately updated.
All of that happens in a single operation.
That is how midPoint works.
MidPoint is not a human.
It will never procrastinate (unless explicitly instructed do to so).
MidPoint will not postpone the operation for later if the operation can be executed immediately.
MidPoint tries to get the data right on the first try.
Therefore there no specialized propagation or provisioning tasks that you might know from older IDM systems.
MidPoint does not need them.

There are other advantages in doing everything in one operation.
It is all one operation therefore midPoint knows all the details: what was the cause, what is the effect, what exactly has been changed.
This is important for troubleshooting.
Some IDM systems decouple the cause and the effect.
Such a divided approach may have its advantages, but it is an absolute nightmare when an engineer needs to figure out why a certain effect happened.
But midPoint has both the cause and the effects correlated together in a single operation.
Therefore it is much easier to figure out what is going on.
And it can also be neatly recorded in the audit trail.
And there is another huge advantage: midPoint knows exactly what has been changed.
This means that midPoint does not only know the new value of a property.
MidPoint knows also the old value and values that were added or removed.
This is a complete description of the change that we call a _delta_.
This is recorded at the beginning of the operation and propagated all the way until the operation is done.
Therefore the mappings may be smart.
This approach enables a lot of interesting behavioral patterns.
For example, it is quite easy for midPoint to implement the "last change wins" policy.
In this case midPoint will simply overwrite only those attributes that are really changed in operation.
MidPoint can leave other values untouched.
In fact, this is the default behavior of midPoint.
And it is a very useful behavior during deployment of a new IDM system.

Careful processing of the operations allows configurations that are not feasible with older IDM systems, e.g. a resource that is both a source and a target.
In fact a lot of IDM systems can have resource that is both a source and a target - as long as it is a source for one attribute and a target for another attribute.
But midPoint can live with a resource where the same attribute is both a source and a target.
And in fact there may be many sources and many targets for the same property at the same time.
And this is indeed very useful configuration.
Just think about telephone number property.
This is usually something that the user sets up himself.
This may be set up by some kind of specialized self-service, it may be updated by a call center call, the user may update that in his Active Directory profile ... there are many ways how this information is changed.
But we want this property to be consistent.
We want telephone number to be the same everywhere.
And we do not care where it was changed.
We just want to propagate the last change from anywhere to all the other systems.
MidPoint can easily do this.
Just specify both inbound and outbound mappings for the same attribute:

[source,xml]
----
<attribute>
    <ref>ri:mobile</ref>
    <outbound>
        <source>
             <path>$focus/telephoneNumber</path>
        </source>
    </outbound>
    <inbound>
        <target>
             <path>$focus/telephoneNumber</path>
        </target>
    </inbound>
</attribute>
----

In this case the change in user property `telephoneNumber` will be propagated to the account attribute `mobile` (outbound change).
But also a change in the account attribute `mobile` will be propagated back to user property `telephoneNumber` (inbound change).
Last change wins.
A clever reader certainly grumbles something about infinite loops now.
But do not worry.
MidPoint can see complete operation context, both inbound and outbound sides.
Therefore midPoint knows when to stop processing the operation.
There are even mechanism how to avoid loops caused by connectors detecting changes caused by the connector itself.
MidPoint will break those loops automatically.

TIP: Synchronization and provisioning are in fact almost the same mechanism applied in a different direction.
Then why there are two sections in the resource configuration?
Why there is `schemaHandling` and `synchronization`?
Why not just one?
The answer is simple: history.
No software is created perfect on day one.
Similarly to other software systems, midPoint went through an evolutionary process of continuous improvement.
MidPoint had a very good design at the beginning.
Looking back at the initial design, now it is quite clear that almost all of midPoint developments were correctly foreseen and accounted for in the design.
However, there are occasional mistakes.
The initial midPoint data model design expected that there will be major differences between synchronization and provisioning mechanisms.
Therefore there were two sections, one for each mechanism.
But midPoint evolution improved the initial design and we have found a way how to unify synchronization and provisioning mechanisms into one.
However, we have not modified the initial data model because we wanted to keep compatibility.
Having two sections instead of one is only a cosmetic imperfection.
It does not cause any major trouble.
But incompatible change would certainly affect continuity of midPoint deployments.
And we highly value midPoint continuity and upgradeability.
Therefore the two sections remained to this day.
However, they will not remain there forever.
We are not going to dwell on old mistakes for too long.
These two section will be reunited once there is a proper time to make incompatible changes.
Which will probably happen in the future when the time comes to release midPoint 5.0.

== Synchronization Strategies

Synchronization is simple in theory.
However, as usual, the devil is in the details.
Similarly to provisioning, there is no one single "synchronization protocol" that would work for all the source systems.
Every system type has its own way to synchronize data.
Some systems (such as LDAP) even have several mechanisms.
And then there are source systems that have no practical way how to implement synchronization.
We would refer to such methods as _synchronization strategies_.

Specific details of each synchronization strategy is an internal matter of connector implementation.
The strategy is configured on connector level and the details are, theoretically, hidden inside the connector.
MidPoint does not know and does not need to know what synchronization strategy is used.
That might work in an ideal world.
But we live in a practical world and there are many details that leak through the _synchronization_ abstraction.

Let us take LDAP as an example.
LDAP is, theoretically, a standard.
However, the standard does not specify any synchronization mechanism.
There is experimental RFC 4533, however it is not widely adopted.
But synchronization capabilities are needed and every major LDAP server provides some mechanisms.
Some mechanisms are quite good, some are not.
There is the ancient "Retro change log", going back to Netscape/iPlanet LDAP servers, but still used today.
Active Directory has its own "DirSync" synchronization mechanism.
OpenLDAP has yet another mechanism based on the access log.
There is RFC 4533, which is used so rarely that there was no request to implement it in midPoint LDAP connector.
And then there is a "catch all" synchronization that looks for recent changes based on `modifyTimestamp`.

In theory, all the synchronization strategies above should be equivalent.
But they are not.
For example, some variants of "Retro change log" synchronization cannot reliably detect rename operations.
There may be problems with delete operations as well, especially if coupled with rename operations.
Almost every mechanism has its quirks.
And then there is the `modifyTimestamp`, which is the most problematic of all.

Unfortunately, it is quite common to use a synchronization strategy based on last modification timestamp.
Not just for LDAP, but also for database tables and other types of source systems.
This is perhaps understandable, as this is a very simple mechanism.
However, it has a lot of problems.
The obvious problems can be caused by de-synchronized time on network, although in the age of Network Time Protocol (NTP) this should not be a problem.
The other problem is a timestamp granularity.
If the timestamp is granular to one second, that can be a big problem.
One second is a very long time for a computer.
A lot can happen in one second.
Therefore the connector has to include the "boundary" second to both consecutive synchronization runs, which means that the records may be processed twice.
Going for millisecond granularity makes the problem less severe, but the problem is still there.

However, the worst problem is that this strategy cannot detect deleted objects.
Deleted objects are not there anymore, they do not have last modification timestamp, therefore they will not be included the search.
This means that there must be a reconciliation process running together with synchronization.
But wait a minute, it is usually recommended running reconciliation anyway, as a form of "safety net", isn't it?
It is, but the difference is in the timing.
It is one thing to run reconciliation once a week to make sure that no records were missed.
Yet, it is a completely different thing to run reconciliation every hour to make sure deleted objects are properly handled.
This makes a huge difference, especially for deployments with millions of entries.
Strategies based on last modification timestamp may look like a good idea at the beginning.
However, they usually turn into a major liability in the long run.
Avoid them if you can.

// TODO LATER: Maybe mention problems with backup/restore and synchronization?
// TODO LATER: Maybe mention messaging-based synch and how (un)reliable it can be?

The bottom line is, that synchronization strategies are not created equal.
In fact, the individual strategies tend to have vastly different characteristics.
Our advice is to learn how each synchronization strategy works, what are the limitations and when it fails.
Also, avoid the use of strategies based on last modification timestamp if there is any other viable alternative.

== Mapping and Expression Tips and Tricks

Mappings and expressions form a very powerful mechanism.
In fact, most of midPoint configuration is about setting up correct mappings.
However, with great power comes great responsibility and mappings may look a bit intimidating at a first sight.
Fortunately, there are some tips and tricks that make the life with mappings and expressions a bit easier.

Most mappings are aware of the context in which they are used.
Therefore paths of mapping sources and targets can be shortened - or even left out entirely.
Activation and credential mappings used in the HR feed example are the obvious cases.
But even paths in ordinary mappings may be shortened.
For example take the outbound mapping source:

[source,xml]
----
    <outbound>
        <source>
             <path>$focus/telephoneNumber</path>
        </source>
    </outbound>
----

As the mapping knows that its source is a focus (user) the definition may be shortened:

[source,xml]
----
    <outbound>
        <source>
             <path>telephoneNumber</path>
        </source>
    </outbound>
----

Typical midPoint deployment has tens or hundreds or mappings.
Deployments with thousands of mappings are definitely feasible.
There are two things that can make maintaining the mappings easier.
Optionally, you can specify the mapping name.
Mapping name will appear in the log files and some error messages.
It may be easier to identify which mapping is causing problems or it may help locate the trace of mapping execution in the log file.
Mapping can also have a description.
The description can be used as a general-purpose comment or a documentation explaining what the mapping does.

[source,xml]
----
<attribute>
    <ref>ri:mobile</ref>
    <outbound>
        <name>ldap-mobile</name>
        <description>
            Mapping that sets value for LDAP mobile attribute based on
            user’s telephone number.
        </description>
        <source>
             <path>$focus/telephoneNumber</path>
        </source>
    </outbound>
</attribute>
----

Mappings can become quite complex.
There may be multi-line scripting expression in the mapping and it may not entirely obvious what is the input and output.
Therefore each mapping and each expression have an ability to enable tracing:

[source,xml]
----
<attribute>
    <ref>ri:mobile</ref>
    <outbound>
        <trace>true</trace>
        <source>
             <path>$focus/telephoneNumber</path>
        </source>
        <expression>
            <trace>true</trace>
            <script>
                <code>...</code>
            </script>
        </expression>
    </outbound>
</attribute>
----

If tracing is enabled then the mapping or expression execution will be recorded in the log files.
Tracing can be enabled at both mapping level and expression level.
Mapping tracing is shorter.
It provides overview of the mapping inputs and outputs.
Expression-level tracing is much more detailed.

However, even this level of tracing may not be enough to debug expression code.
Therefore there is a special expression function for logging.
Arbitrary messages may be logged by script expression code:

[source,xml]
----
    <expression>
        <script>
            <code>
                ...
                log.info("Value of foo is {}", foo)
                ...
            </code>
        </script>
    </expression>
----

Generally speaking, troubleshooting of mappings may be quite difficult as it is often intertwined with midPoint internal algorithms.
But there are ways how to do it.
The <<90-troubleshooting.adoc#90-troubleshooting,Troubleshooting>> chapter provides much more details on this.

== Expression Functions

Expressions in general and scripting expressions in particular are the place where most midPoint customization takes place.
Scripting expressions are able to execute any code in a general-purpose programming language.
Therefore the script can transform the data in any way or it can execute any function.
Quite naturally there are functions that are frequently used in the scripts.
Therefore midPoint provides convenient scripting libraries full of useful methods ready to be used in scripting expressions.

There are two scripting libraries that are used very often:

* *Basic script library* provides very basic functions for string operations, object property retrieval, etc.
These are simple, efficient stand-alone functions.
These functions can be used in every expression.

* *MidPoint script library* provides access to higher-level midPoint functions contain IDM-specific and midPoint-specific logic.
This library can be used to access almost all midPoint functionality.
But there are few places where this library may not work reliably (e.g. correlation expression).

The libraries are designed to be very easy to use from the scripting code.
While the specific details how to invoke the library depend on the scripting language, the libraries are usually accessible by the use of `basic` and `midpoint` symbols.
Function `norm()` from the basic library can be invoked in a Groovy script like this:

[source,xml]
----
    <expression>
        <script>
            <code>
                ...
                basic.norm('Guľôčka v jamôčke!')
                ...
            </code>
        </script>
    </expression>
----

Invocation of the libraries from JavaScript and Python is almost the same and we are sure that a clever reader will have no trouble figuring that out.
What is more difficult to figure out is which functions the libraries provide.
For that purpose there is a page in midPoint wiki that lists all the libraries and this page also has a link to library function documentation.
Look for https://wiki.evolveum.com/display/midPoint/Script+Expression+Functions[Script Expression Functions] page in midPoint wiki.

Only two libraries were mentioned in this section so far.
However, this is not a whole story.
A clever reader has certainly figured out that the logging function described in previous section is also a scripting library.
And there may be more libraries in the future.

=== Resource Capabilities

The systems that midPoint connects to are not created equal.
In fact, those systems significantly differ in their capabilities.
Most systems can create accounts.
But not all of them can delete accounts.
There are systems that keep the accounts forever, the accounts can be just permanently disabled.
And yet another systems cannot enable or disable accounts.
While most systems support password authentication, other system do not.
There is a lot of natural diversity in the provisioning wilderness.
And even the connector may introduce limitations.
Even if target system supports a particular feature, connector may not have appropriate code to use it.
MidPoint needs to take all these differences into consideration when executing synchronization and provisioning operations.

MidPoint refers to these features of the systems and connectors as _resource capabilities_.
Although capabilities may in fact be quite complex, they are essentially just a list of things that a connector and resource can do.
MidPoint is aware of the resource capabilities.
Therefore midPoint can work with resource data correctly. E.g. midPoint will not try to modify account on a read-only resource.

Capabilities are usually automatically discovered by midPoint and everything just works out of the box.
There is usually no extra work to maintain the capabilities.
But sometimes there is a need to tweak the capabilities a bit.
Maybe the connector cannot detect resource capabilities well enough.
Maybe there is a read-only resource, but the connector has no way of knowing this.
Therefore the write capabilities have to be manually disabled in midPoint.
For that reason there are two sets of capabilities:

* *Native capabilities* are capabilities detected by the connector.
Those are always automatically generated by midPoint.
Those capabilities should not be modified by administrator.

* *Configured capabilities* are the capabilities modified by the administrator.
Configured capabilities are used to override native capabilities.
Configured capabilities are usually empty, which means that only native capabilities are used.

There are many ways how the capabilities can be tweaked by the administrator.
But there is one case that is particularly interesting for synchronization and provisioning: simulated activation capability.

MidPoint connectors can be tailored specifically for a particular system. E.g. there are often connectors that are developed specifically for one custom enterprise application.
At the other side of the spectrum are generic connectors that can fit a wide variety of systems and applications.
LDAP, CSV and database table connectors are examples of such generic connectors.
Such connectors are very useful and they are used in almost every midPoint deployment.
However, there is no standardized way how to disable an account in database table or a CSV file.
Various columns and various values are used to represent account activation status.
Quite surprisingly, there is no standardized way how to disable an account in LDAP directory either.
But that is bad news for midPoint.
MidPoint takes a significant advantage from knowing whether account is disabled or enabled.
We had to do something about it.
And we did.
There is way how to tell midPoint which attribute and what values are used to represent account activation status.
Configured activation capability is used for that purpose:

[source,xml]
----
    <capabilities>
        <configured>
            <cap:activation>
                <cap:status>
                    <cap:attribute>ri:active</cap:attribute>
                    <cap:enableValue>true</cap:enableValue>
                    <cap:disableValue>false</cap:disableValue>
                </cap:status>
            </cap:activation>
        </configured>
    </capabilities>
----

Configured capability above specifies resource attribute `active` as the attribute that controls account activation status.
If this attribute is set to value `true` then the account is enabled.
If the attribute is set to value `false` then the account is disabled.
That is it.
Once this configured capability is part of resource definition then midPoint will pretend that the resource can enable and disable accounts.
Attempt to disable account will be transparently translated to modification of attribute active.
But it also works the other way around.
If an account has attribute `active` set to `false` value midPoint will display that account as disabled.
No extra logic or mapping is needed to achieve that.
The capability does it all.

=== Synchronization Example: LDAP Account Correlation

Previous example demonstrated the use of synchronization for HR feed.
That is the most obvious use of synchronization mechanisms.
However, midPoint synchronization is much more flexible than just feeding data to midPoint.
Synchronization can be used even for target resources.
In that case the synchronization is usually used for several purposes:

* *Initial migration:* This is a process of connecting new resource to midPoint.
There are usually accounts that already exist in the resource at the time when a resource is connected to midPoint.
It is likely that at least some accounts correspond to the users that are present in midPoint (e.g. users created from the HR feed).
Therefore the accounts from the resource need to be correlated to the users that already exist in midPoint.
Synchronization is the right mechanism for this.

* *Detection of illegal accounts:* Security policies are usually set up in such a way that only those people that need an account on a particular resource should have that account.
This is known as the _principle of least privilege_.
However, in typical IDM deployment there is nothing that would prohibit system administrator to create any accounts at will.
And this is often desirable because there are emergency situations where full control over the system is crucial.
But even for emergency cases, we want to make sure that the situation is aligned with policies when the emergency is over.
MidPoint can easily do that by scanning the target systems in regular intervals.
Synchronization mechanisms can be used to detect accounts that do not have any legal basis and delete or disable such accounts.
Again, synchronization mechanism can do that easily.

* *Attribute value synchronization:* Accounts in target resources are usually created as a result of midPoint provisioning action.
However, account attribute values are in fact copies of the data in midPoint.
Attribute values can easily be changed by system administrator, may be set to old values during data recovery procedure or they can get out of sync by a variety of other means.
MidPoint can make sure that the attributes are synchronized and that they stay synchronized for a long time.
Synchronization mechanisms are ideal for this purpose.

Older IDM systems used synchronization mostly to get data from the source resources to IDM system.
But synchronization in midPoint is much more powerful.
It can be applied to source systems and target systems, it can pull data, push data, detect inconsistencies and fix them.
Synchronization is a general purpose mechanism.
This is the principle of reuse again.
Synchronization mechanism can be reused for variety of purposes.

In this example we will be using synchronization to connect existing LDAP server to midPoint.
We assume that our midPoint is already connected to the HR system.
We have imported the HR data.
Now we have midPoint users created for all our employees.
And then there is this LDAP server.
It is really important LDAP server.
This server is used by company intranet portal and also by a variety of smaller web applications.
Those applications are using the LDAP server for user authentication and access authorization.
The LDAP server was deployed few years ago.
Initially it was populated by the HR data.
But the LDAP server was managed manually by a system administrator during all these years.
Therefore it is expected that there will be some accounts that belong to former employees.
Also, it might have happened that some accounts are missing.
And it is quite likely that a lot of the accounts have wrong data.

First task is to set up the connector for this resource.
As LDAP servers are used for identity management purpose all the time, MidPoint comes with a really good LDAP connector.
All we need is to set up the resource to use that connector:

[source,xml]
----
<resource oid="8a83b1a4-be18-11e6-ae84-7301fdab1d7c">
    <name>OpenLDAP</name>

    <connectorRef type="ConnectorType">
        <filter>
            <q:equal>
                <q:path>connectorType</q:path>
                <q:value>com.evolveum.polygon.connector.ldap.LdapConnector</q:value>
            </q:equal>
        </filter>
    </connectorRef>
    ...
----

What we can see here is a slightly more sophisticated method to reference the connector.
So far we have seen only a direct reference by OID. This works well for almost all the references in midPoint because OID never changes.
But connectors are a bit tricky.
Objects that represent connectors are dynamically created by midPoint when a connector is discovered.
Therefore the OID is generated at random when midPoint starts.
There is no practical way how a system administrator can predict that OID. But we still want our resource definitions to refer to a particular connector when we import the definition.
Therefore there is an alternative way how to specify object references.
This method is using a search filter instead of direct OID reference.
When this resource definition is imported to midPoint then midPoint will use that filter and look for LDAP connector.
If that connector is found then the OID of that connector is placed in the reference (`connectorRef`).
Therefore the next time midPoint will be using this resource it can follow the OID directly.
This is a very convenient method.
But there are few limitations.
Firstly, the filter is resolved only during import.
That means it is resolved only once.
If the connector is not present at import time then the reference needs to be corrected manually.
Secondly, this approach works if there is only one LDAP connector deployed to midPoint.
This is usually the case.
But the connector framework can contain several connectors of the same type in different versions.
This is a very useful feature for gradual connector upgrades, testing of new connector versions and so on.
But in case that the filter matches more than one object the import will fail.
In that case the connector reference has to be set up manually.

Once we have proper reference to LDAP connector we need to configure the connection:

[source,xml]
----
    ...
    <connectorConfiguration>
        <icfc:configurationProperties>
            <cc:port>389</cc:port>
            <cc:host>localhost</cc:host>
            <cc:baseContext>dc=example,dc=com</cc:baseContext>
            <cc:bindDn>cn=idm,ou=Administrators,dc=example,dc=com</cc:bindDn>
            <cc:bindPassword><t:clearValue>secret</t:clearValue></cc:bindPassword>
            ...
        </icfc:configurationProperties>
        <icfc:resultsHandlerConfiguration>
            <icfc:enableNormalizingResultsHandler>false</icfc:enableNormalizingResultsHandler>
            <icfc:enableFilteredResultsHandler>false</icfc:enableFilteredResultsHandler>
            <icfc:enableAttributesToGetSearchResultsHandler>false</icfc:enableAttributesToGetSearchResultsHandler>
        </icfc:resultsHandlerConfiguration>
    </connectorConfiguration>
    ...
----

This is all very similar to the configuration of the other resource that were already presented in this book.
It should be quite self-explanatory – except perhaps for the configuration of result handlers.
_Result handlers_ are little helpers that come with the ConnId connector framework.
The purpose of the result handlers is to assist simpler connectors in filtering and post-processing search results.
But LDAP connector is no ordinary simple connector.
LDAP connector is mature and full-featured connector that can do everything without any help from such annoying little creatures as those result handlers.
ConnId result handlers do not add any value here.
In fact, they may even be harmful.
LDAP protocol has a lot of peculiarities such as case-insensitivity that applies to almost all the aspects of LDAP data – except for some notable exceptions.
The connector is aware of those peculiarities but the handlers are not.
If the handlers are turned on (which is the default) they may get in the way and ruin the data.
Therefore it is always strongly recommended to explicitly turn off the handler when a full-featured connector is used.

NOTE: The XML example above, as all other examples in this book, is simplified and shortened for clarity.
You will not be able to import the example in this form into midPoint.
For a full importable examples see the files that are supposed to accompany this book.
Please see <<92-additional-information.adoc#92-additional-information,Additional Information>> chapter.

The basic resource configuration above is sufficient to connect to the resource.
Therefore the test connection operation on resource details page should be successful.
This configuration may also be used to list the accounts.
However, LDAP servers support many object classes and midPoint does not yet know which object class represents account.
Therefore we need to add schema handling section to our resource:

[source,xml]
----
    ...
     <schemaHandling>
        <objectType>
            <kind>account</kind>
            <displayName>Normal Account</displayName>
            <default>true</default>
            <objectClass>ri:inetOrgPerson</objectClass>
            <attribute>
                <ref>ri:dn</ref>
                <displayName>Distinguished Name</displayName>
                <limitations>
                    <minOccurs>0</minOccurs>
                </limitations>
                <outbound>
                    <source>
                        <path>$focus/name</path>
                    </source>
                    <expression>
                        <script>
                            <code>
                                basic.composeDnWithSuffix('uid', name,
                                                  'ou=people,dc=example,dc=com')
                            </code>
                        </script>
                    </expression>
                </outbound>
            </attribute>
            ...
----

There should be outbound mapping for each mandatory LDAP attribute for the `inetOrgPerson` object class.
Those mapping are very typical for a target resource definition.

Once we set up the schema handling, we should be able to conveniently list LDAP accounts in midPoint.
However, we need to switch to the _Resource_ view instead of _Repository_ view.
The accounts are stored in the LDAP server and midPoint can access them.
Therefore the accounts are listed in the _Resource_ view.
But midPoint have not processed the accounts yet.
Therefore there are no account shadows in midPoint repository.
And that is the reason that the _Repository_ view is empty.
But now we are going to do something about it.

We are going to import (or reconcile) the resource accounts.
But if we try to do this now nothing would really happen.
The accounts are not linked to users therefore midPoint will not synchronize the attributes.
And midPoint was not told to do anything with the accounts.
Therefore midPoint will do nothing.
That is one of midPoint principles: midPoint will not change the accounts in any way unless it is explicitly told to do so.
Default midPoint configuration is to do nothing.
We would rather do nothing than to destroy the data.

Before we can import the accounts we need to set up the synchronization configuration for this resource.
There are accounts in the LDAP server that should belong to users that already exist in midPoint.
We want to link them.
But we do not want to do the linking manually.
We would rather set up a correlation expression that does this automatically:

[source,xml]
----
    ...
     <synchronization>
        <objectSynchronization>
            <objectClass>ri:inetOrgPerson</objectClass>
            <kind>account</kind>
            <intent>default</intent>
            <focusType>UserType</focusType>
            <enabled>true</enabled>
            <correlation>
                <q:equal>
                    <q:path>employeeNumber</q:path>
                    <expression>
                        <path>$projection/attributes/employeeNumber</path>
                    </expression>
                </q:equal>
            </correlation>
            ...
----

This correlation expression is going to match account attribute `employeeNumber` and user property that is also named `employeeNumber`.
Simply speaking: if account and user employee numbers match then we assume that they should be linked.
In that case midPoint decides that synchronization situation is unlinked (they should be linked, but they are not yet linked).
We want midPoint to link the account in this case, therefore we define appropriate reaction:

[source,xml]
----
            ...
            <reaction>
                <situation>unlinked</situation>
                <synchronize>true</synchronize>
                <action>
                    <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/action-3#link</handlerUri>
                </action>
            </reaction>
            ...
----

This will take care of accounts for whose we can find an owner.
But what to do with other accounts?
We will do nothing about that yet.
Therefore we do not need to define any other reactions.
This may be somehow surprising.
We do not want illegal accounts, do we?
Then perhaps we would like to see a reaction to delete unmatched accounts, right?
That would be a good approach, but it is just too early for this.
We do not want to delete unmatched account just now.
There may be accounts that are perfectly legal, just the employeeNumber attribute is missing or mistyped.
Data errors like those happen all the time, especially when the data were managed manually.
We do not want to over-react and start deleting accounts too early.
Therefore we will go just with this one synchronization reaction for now.

Now it is the right time to start import or reconciliation task.
After the task is finished the situation may look like this:

image::05-04-reconciliation-ldap-unmatched.png[OpenLDAP accounts]

It looks like we had quite a good data in the LDAP server.
Most of the accounts were successfully correlated and linked to their owners.
But there are few accounts that were not correlated.
Those accounts ended up in unmatched situation.
You can resolve this situation by manually linking the unmatched accounts to their users.
Simply click on the small triangle button next to the unmatched entry and select _Change owner_ from the context menu.
Then select the right user (Isabella Irvine) in the dialog that appears.
After that the account is linked to the user.
Repeat this process to link all unmatched accounts.

There is one interesting thing in the screenshot above.
Have a look at the LDAP account identified by `uid=carol`.
While most other accounts have their uid value taken from the surname of the user, this account is an exception.
Even though the uid is obviously wrong, midPoint have linked the account correctly to the user (Carol Cooper).
The reason is that we have set up midPoint to use employeeNumber for correlation.
The result is that even accounts whose usernames violate the convention can be automatically linked to their owners - as long as there is any reliable piece of information that can be used for correlation.

When all the accounts are linked to their owners, it is the right time to complete the synchronization policy.
Now we can tell midPoint to delete any unmatched account.
That is the case when an illegal account is created in LDAP server.
We can also tell midPoint to unlink any account that was deleted in LDAP server:

[source,xml]
----
            ...
            <reaction>
                <situation>unmatched</situation>
                <action>
                    <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/action-3#deleteShadow</handlerUri>
                </action>
            </reaction>
            <reaction>
                <situation>deleted</situation>
                <action>
                    <handlerUri>http://midpoint.evolveum.com/xml/ns/public/model/action-3#unlink</handlerUri>
                </action>
            </reaction>
            ...
----

There may be some accounts in the LDAP server that have wrong attribute values.
By "wrong" we mean that the attributes have different values than the values that are computed by the outbound mappings.
But midPoint will not correct those values just yet.
Remember the midPoint principle that it will not change the account unless we have explicitly told to do so?
Those accounts are in the `linked` situation.
And we have not configured any reaction for this situation.
Therefore now we need to tell midPoint to synchronize the values:

[source,xml]
----
            ...
            <reaction>
                <situation>linked</situation>
                <synchronize>true</synchronize>
            </reaction>
            ...
----

A clever readers is now surely wondering whether we have forgotten something.
And indeed we have.
Attribute values are synchronized by running reconciliation process.
But our outbound mappings will not work in reconciliation.
They do not have any explicit definition of strength, therefore midPoint assumes `normal` strength.
Those mappings are supposed to implement the _last change wins_ strategy.
Therefore reconciliation cannot overwrite the account data as midPoint does not know whether it was account attribute or user property that was the last to change.
If midPoint is not sure about something then it will do nothing.
We do not want to destroy the data.
Therefore what we need to do now is to let midPoint know that we really mean it, that the mappings are really `strong`:

[source,xml]
----
            ...
            <attribute>
                <ref>ri:cn</ref>
                <displayName>Common Name</displayName>
                <limitations>
                    <minOccurs>0</minOccurs>
                    <maxOccurs>1</maxOccurs>
                </limitations>
                <outbound>
                    <strength>strong</strength>
                    <source>
                        <path>$focus/fullName</path>
                    </source>
                </outbound>
            </attribute>
            ...
----

Clever reader is uneasy once again.
What is this `limitations` thing here?
Simply speaking, the limitations specify that the attribute is optional (`minOccurs=0`) and that it is single-valued (`maxOccurs=1`).
But, isn’t midPoint supposed to be completely schema-aware and figure that all by itself?
Yes, it is.
And in fact, that is the reason why we need to override the information from the schema using this `limitations` element here.
The `cn` attribute is specified in LDAP schema as a mandatory attribute.
However, we have just specified outbound mapping for that attribute.
Therefore even if midPoint user does not provide any value for attribute `cn`, we can still determine that value by using the expression.
Therefore even though LDAP schema specifies attribute `cn` as mandatory, we want to present that attribute as optional in midPoint.
Hence the `minOccurs` limitation.
And the `maxOccurs` limitation is immediately obvious to anyone who is intimately familiar with LDAP peculiarities.
In the LDAP world, almost everything is multi-valued by default.
Therefore even commonly used attributes for account identifiers and names are multi-valued.
Nobody is really using them as multi-valued attributes because vast majority of applications will probably explode if they ever encounter two values in the `cn` attribute.
But those attributes are formally defined as multi-valued in LDAP schema and that is what midPoint gets from LDAP connector.
The `maxOccurs` limitation is overriding the schema and forcing midPoint to handle this attribute as if it was single-value attribute.

That is all.
Now you can schedule reconciliation tasks to keep an eye on the LDAP server.
The task will correct any attribute values that step out of line and delete any illegal accounts.
This is how synchronization tasks can be useful even in case of pure target resources.

However, there is one last word of warning.
Those accounts were synchronized and linked to existing midPoint users.
The accounts were not created by midPoint.
Therefore there is nothing in midPoint that would say that those accounts should exist.
In midPoint parlance there are no _assignments_ for those accounts.
MidPoint makes clear distinction between policy and reality.
Therefore midPoint is aware that those accounts exist, but there is no policy statement that would justify their existence.
By default midPoint does nothing and it will let the accounts live.
The accounts will be created or deleted only if there is an explicit change in the assignments.
There is no such change now, therefore the accounts are not deleted.
But this is a fragile situation.
Accounts that are linked but not assigned can easily get deleted if midPoint administrator is not careful.
Of course, there are methods to handle such situations.
One way would be to create the assignments together with the links.
Those that are interested in this method should look up keyword "legalize" in midPoint wiki.
But there are much better methods how to handle this.
Perhaps the best approach would be to utilize the roles (RBAC).
This is the topic of the <<07-rbac.adoc#07-rbac,Role-Based Access Control>> chapter later.
But there are still more things to learn about synchronization until we get there.

=== Reconciliation

Reconciliation is a process of comparing current state of an account (reality) to a desired state of the account (policy).
Reconciliation does not only compare the accounts, it is fixing the inconsistencies.
Reconciliation can correct wrong data on resources.
But it also works the other way.
It can correct the data in midPoint.
Therefore, reconciliation is one of the most useful tools in the identity management toolbox.

Reconciliation can be used in a variety of ways.
Reconciliation can be initiated for one specific user by using midPoint user interface.
In that case midPoint compares the values of all user’s accounts to the values that were computed using the mappings.
If there is difference midPoint corrects account values.
This approach is perfect for testing reconciliation setting on just a single user.
This feature is also useful for fixing values of one specific user.

Reconciliation of a specific user may be useful, but it is an ad-hoc approach.
We usually favor systemic approaches in identity management.
Therefore reconciliation can be used in a form of a reconciliation task.
Reconciliation task lists all the accounts on the resource and then it reconciles each account, one by one.
This is a way how to keep all resource accounts continuously synchronized.

There is a couple of things about reconciliation that can be somehow surprising.
Firstly, reconciliation of an account may cause modification of a user.
This happens if there are inbound mappings for that account.
This is perhaps quite expected.
But if user is changed then such change may propagate to other accounts on other resources, usually by the means of outbound mapping.
MidPoint does not like procrastination and therefore it will try to execute those changes immediately.
But it means that reconciliation of one account may cause changes to other accounts.
Which makes a lot of sense, yet it may be quite surprising.
Secondly, reconciliation will skip any normal-strength mappings.
We have already explained the reasons for that, but this is something that can surprise even an experienced midPoint engineer from time to time.
If we are sure that we want the mapped value to be present in the account all the time then strong mappings are the way to go.

A curious reader that has already explored midPoint user interface has surely noticed _recompute_ function.
What recompute does looks almost exactly the same as reconciliation.
But there are subtle differences.
Recompute will not force the fetch of account data.
In this case the account attributes will be fetched from the resource only if midPoint inevitably needs them for the computation.
This usually happens if `weak` or `strong` mappings are used.
But if there are `normal` mappings only then recompute may not read account data.
MidPoint will compare and correct account attribute values only for those accounts that are fetched from resource during this process.
That is how recompute works.
The purpose of a recompute is to correct data of midPoint users, which means evaluation of object templates and other policies.
Correcting account data is more or less just a side effect of a recompute.
On the other hand, reconciliation always tries to read all the accounts regardless whether they are needed for computation or not.
Therefore all the attributes on all the accounts are fixed.
That is the purpose of reconciliation: correct the account data.

There is yet another difference between recompute and reconcile _tasks_.
The purpose of a recompute task is to correct user data.
Therefore recompute task will iterate over midPoint users.
Recompute task will not detect new accounts on the resource and it may even overlook if an account is deleted.
But reconciliation task is different.
In fact reconciliation task has several stages.
Main reconciliation stage lists all resource accounts.
It determines owner of each account, compare the attributes and correct them.
But as this process iterates over real accounts on a resource, it can also detect new accounts.
When the main stage is completed then the next phase is looks at account shadows stored in midPoint.
The task looks for shadows that have not been processed in the main phase.
Those are accounts that used to be on the resource some time ago but that have disappeared.
That is how reconciliation detects deleted accounts.

=== Deltas

Reconciliation is really useful mechanism.
It is reliable and thorough, but it is also quite slow and it consumes o lot of computational and network resources.
And there are reasons why reconciliation is such a heavyweight beast.
Reconciliation works with _absolute_ state of accounts.
It means that reconciliation is reading all the accounts with all the values of all the attributes.
Then it recomputes everything.
Even those attributes and values that were not changed are recomputed.
This is a very traditional and reliable way of computation and that is also the way how the most of older identity management systems work.

But there is also a better way.
If we know that just one attribute was changed, we can recompute that single attribute only.
We do not need to care about other attributes.
And if we know that attribute foo has changed in such a way, that there is a new value bar then it gets even better.
We just need to recompute the value bar and do not care about any other values.
This is what we like to call a _relative change_.
We just care about the values that were changed.
That is how midPoint works internally.
We could say that MidPoint is _relativistic_.

This is where _delta_ comes in.
Delta is a data structure that describes the change of a single midPoint object.
_Add_ delta describes a new midPoint object that is about to be created.
_Modify_ delta describes existing midPoint object where some properties have changed.
_Delete_ delta describes an object that is going to be deleted.
This is a very powerful mechanism.
Just remember that everything in midPoint can be represented as an object: user, account, resource, role, security policy … everything.
Therefore delta can represent any change.
It may be a change of user password, deletion of an account, change of connector configuration or introduction of a new password policy.
If all the changes can be represented in a uniform way then they can also be handled in a uniform way.
Therefore it is easy for midPoint to record all the changes in an audit trail – including configuration changes.
It is easy to route any change through an approval process.
And so on.
MidPoint can create a relatively simple mechanisms to handle changes and then those mechanisms can be applied to changes of (almost) any object.

Let’s have a closer look at an anatomy of a delta.
There three types of delta: _add_, _modify_ and _delete_.
_Add delta_ is quite simple.
It contains a new object to be created.

image::05-05-delta-add.png[Add delta]

_Delete delta_ is even simpler.
It contains just object identifier (OID) of an object to be deleted.

image::05-06-delta-delete.png[Delete delta]

Last one is _modify delta_.
This delta contains a description of modified properties of an existing object.
But as the object can change in a variety of ways the modify delta is the most complex of the tree.
Modify delta contains a list of _item deltas_.
Each item delta describes how a particular part of an object changes.
For example following delta describes that a new value `pirate` is added to a user property `employeeType`.

image::05-07-delta-modify-add.png[Modify delta: add]

The item delta may have three modification types: _add_, _delete_ and _replace_.
_Add modification_ means that new value or values are added to an item.
_Delete modification_ means that value or values are removed from an item.

image::05-08-delta-modify-delete.png[Modify delta: delete]

In both _add_ and _delete_ cases the values that are not mentioned in the delta are not affected.
However, _replace_ modification is different.
This means that all existing values of the item are going to be discarded and they are replaced with the value or values from the delta.

image::05-09-delta-modify-replace.png[Modify delta: replace]

The deltas are designed to work with both single-valued and multi-valued items.
In fact _add modification_ and _delete modification_ deltas are specifically designed with multi-value items in mind.
Those deltas can work efficiently even in cases that there is a multi-valued attribute that has a very large number of values.
And there is a good reason for this.
Multi-valued properties are quite common in the identity management field.
Just think about how roles, groups, privileges and access control lists are usually implemented.
Everybody that ever managed a large group in LDAP server will surely remember that experience in vivid colors.
But midPoint is designed to handle situations like those.

Everything in midPoint is designed to work with deltas: user interface, mappings, authorizations, auditing … all the way down to the data storage components.
Mappings are designed in a relativistic ways.
That is the reason why we need to explicitly specify sources of the mapping.
Mapping source definitions are matched with items in the delta to control execution of the mapping.
Deltas permeate entire midPoint computation.
Deltas are input to the mappings, but mapping produce other deltas as output.
Therefore we can have a complete chain: deltas that are result of inbound mappings is applied to the user object, but those deltas are also input to outbound mappings.
Everything is _relativistic_ in midPoint.

This might seem to be a bit over-complicated at the beginning.
But do not worry.
You will get used to it.
And clearly, this approach has major advantages.
But a clever reader does not seem to be impressed.
How can this relativistic approach conserve any significant portion of computational resources?
We usually fetch the entire account from the resource anyway.
Therefore there is no harm to recompute all the attributes.
The computation itself is fast, it is the fetch operation that is slow.
Isn’t it?
The clever reader is, of course, right.
Or partially right at the very least.
Most resources really fetch all the account attributes in a single efficient operation.
And for those cases there is no big increase in efficiency if we go with the relativistic methods.
But there are exceptions.
For example some resources will not return all the values of big attributes, e.g. all the members of a large group.
Additional requests are needed to fetch all the values – and there may be a lot of requests if the group is really large.
Relativistic approach has significant benefit in those cases.
And the benefits will be even more obvious when we get to the live synchronization in the next section.
But performance is not the primary motivation for the relativistic approach.
There is one extremely strong reason to go relativistic: data consistency.
Consistency is something that brings ugly nightmares to many engineers that try to design distributed system.
And identity management solution is in fact a distributed system.
But it is a very loosely-coupled distributed system.
There is no support for locking or transactions in the connector.
And even if there was some support, the vast majority of resource cannot provide those consistency mechanisms on their identity management APIs.
This means that midPoint cannot rely on traditional consistency mechanisms.
And that is why relativistic approach is so useful.
Relativistic computation has a very high probability of achieving correct result even without locking or transactions.
This is more than acceptable for typical identity management deployments.
And for those rare cases where relativistic computation can fluctuate there is always reconciliation as a last resort.
But thanks to the relativistic nature of midPoint the need for reconciliation is significantly reduced.

That was a lot of long words, but clever reader seems to be satisfied now.
At least for a while.
But there is quite a simple summary: relativistic approach of midPoint can do miracles.
For example, midPoint resource can be both sources and targets, even a single attribute can be both source and target of information.
It is the relativistic approach that allows features like this.
The principle of relativity is relatively simple.
But its effect in midPoint is nothing short of being revolutionary.

=== Live Synchronization

MidPoint has a range of synchronization mechanisms.
Slow, brutal but reliable reconciliation is at one end.
Live synchronization is on the other.
Live synchronization is a lightweight mechanism that can provide almost-real-time synchronization capabilities.
Live synchronization is specifically looking for recent changes on a resource.
When such changes are detected, live synchronization mechanisms process those changes immediately.
The synchronization delay is usually in order of seconds or minutes if live synchronization is used properly.

Unlike reconciliation, live synchronization is not triggered manually.
That would make very little sense.
Live synchronization works in a long-running task repeatedly looking for fresh changes in short time intervals.
If a resource is configured for synchronization then all that is needed to run live synchronization is to set up a live synchronization task.
MidPoint user interface can be used to do that easily.
And an example of live synchronization task was provided in the HR feed section above.

Live synchronization task wakes up at regular intervals.
Each time the task waves up it invokes the connector.
Connectors that are capable of live synchronization have special operation that is used to get fresh changes from the resource.
The connector can support any reasonable change detection mechanism – in theory.
But two mechanisms are commonly used in practice:

* *Timestamp-based synchronization:* Resource keeps track of last modification timestamp for each account.
The connector looks for all accounts that have been modified since last scan.
This is very simple and relatively efficient method.
But it has one major limitation: it cannot detect deleted accounts.
If an account is deleted then there is no timestamp for that account and therefore the connector will not find it in the live synchronization scan.

* *Changelog-based synchronization:* Resource keeps a “log” of recent changes.
The connector is looking at the log and it is processing all the changes that were added to the log since the last scan.
This is a very efficient and flexible method.
But it is not simple.
And not many systems support it.

All live synchronization methods need to keep the track of what changes are "recent", i.e. which changes were already processed by midPoint and which were not processed yet.
There is usually some value that needs to be remembered by midPoint: timestamp of last scan, last sequence number in the change log, serial number of last processed change and so on.
Each connector has a different value with a connector-specific meaning.
MidPoint refers to those values as "tokens".
The most recent token is stored in the live synchronization task.
That is how midPoint keeps track of processed changes.
There are (hopeful quite rare) cases when resource and midPoint token get out of alignment.
This may happen in cases such as the resource database is restored from a backup, if network time gets out of synchronization and so on.
If that happen then deleting the token from the live synchronization task is usually all it takes to get the synchronization running again.

Live synchronization is fast and very efficient.
But it is not entirely reliable.
MidPoint may miss some changes.
This is quite a rare situation, but it may happen.
Reconciliation will surely remedy the situation in such a case.
Just remember, all the synchronization mechanism share the same configuration.
And it is perfectly acceptable to run live synchronization and reconciliation on the same resource at the same time.
But of course, it would be a good idea to run reconciliation less frequently than live synchronization.

=== Conclusion

Synchronization is one of the most important mechanisms in the entire identity management field.
Primary purpose of synchronization is to get the data into midPoint.
And that is really good approach when an identity management deployment begins: get your data into midPoint first.
Get the data from the HR system.
Correlate that with Active Directory.
Connect all the major resources to midPoint and correlate the data.
MidPoint does not need to make any changes at this stage.
In fact, it is perfectly good approach to make all the resource read-only at this stage.
The point is to let midPoint see the data.
But why do we need that?

* We will see what is the real quality of the data.
Most system owners have at least some idea what data sets are there.
But it is almost impossible to estimate data quality until the data are processed and verified.
That is exactly what midPoint can do at this stage.
This is essential information to plan data cleanup and sanitation.

* We will learn how many accounts and account types are there.
It is perhaps quite obvious that there are employee accounts.
But are there accounts for contractors, suppliers, support engineers?
Are those accounts active?
What is the naming convention?
Do system administrators use employee accounts for administration.
Or are they using dedicated high-privilege accounts?
This information is crucial to set up provisioning policies.

* We will learn distribution of accounts and their entitlements.
Do all employees have accounts in Active Directory?
Are there any frequently-used groups?
How does organizational structure influence the accounts?
This information is very useful to design a role-based access control structures and other policies.

* We will surely learn some security vulnerabilities.
Are there orphaned accounts that should have been deleted long time ago?
Are there testing accounts that were left unattended after the last night-time emergency?
Indeed, there is no security without identity management.

This is a good start.
But even if this is all that you do in the first step of the deployment it is still a major benefit.
You will get better visibility and with that comes better security.
And you have the data to analyze your environment and plan next step of the identity management deployment.
You won’t be blind any longer.
And that is really important.
It is indeed a capital mistake to theorize before one has data.

////
Tips for extension:
* CRM resource, with some rogue accounts, manual correlation, orphan detection
////

